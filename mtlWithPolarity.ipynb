{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2510329,"sourceType":"datasetVersion","datasetId":1520310},{"sourceId":8312857,"sourceType":"datasetVersion","datasetId":4938334}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-06T16:04:23.280095Z","iopub.execute_input":"2024-05-06T16:04:23.280417Z","iopub.status.idle":"2024-05-06T16:04:23.658962Z","shell.execute_reply.started":"2024-05-06T16:04:23.280392Z","shell.execute_reply":"2024-05-06T16:04:23.658017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pandas\n!pip install emoji\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:23.660535Z","iopub.execute_input":"2024-05-06T16:04:23.660902Z","iopub.status.idle":"2024-05-06T16:04:48.858868Z","shell.execute_reply.started":"2024-05-06T16:04:23.660877Z","shell.execute_reply":"2024-05-06T16:04:48.857824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PRE PROCESSING\n\nimport re\nimport emoji\nimport nltk\nfrom nltk.corpus import stopwords\n\nnltk.download('stopwords')\n\ndef pre_process(text):\n\n    text = text.replace('\\n', '')\n    text = text.replace('\\t', '')\n    text = text.replace('\\s', '')\n    text = re.sub(r'https?://\\S+|www\\.\\S+', 'url', text) # to remove url\n    text = re.sub(r'\\S+@\\S+', 'email', text) # to remove email\n    text = re.sub(r'@\\S+', 'user', text) # to remove user\n    text = re.sub(r'\\d+%', 'percentage', text) # to remove percentange\n    text = re.sub(r'\\$\\d+(\\.\\d+)?', 'money', text) # to remove money\n    text = re.sub(r'\\d+/\\d+/\\d+', 'date', text) # to remove dates\n    text = re.sub(r'\\d+:\\d+', 'time', text) # to put time in the place of time\n    text = re.sub(r'\\d{3}-\\d{3}-\\d{4}', 'phone', text) # phone number\n    text = re.sub(r'#(\\S+)', lambda x: ' '.join(re.findall(r'[A-Z]?[a-z]+', x.group())), text)# to remove hashtags\n    text = re.sub(r'\\b(\\w+?)\\1{2,}\\b', r'\\1', text) # to remove elongated words\n    text = emoji.demojize(text) # to remove emojies\n    text = text.lower() # to convert into lower case\n\n    stop_words = set(stopwords.words('english'))\n    words = text.split(\" \")\n    final_words = [word for word in words if word not in stop_words]\n    final_sen = ' '.join(final_words)\n\n    return final_sen","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:48.860422Z","iopub.execute_input":"2024-05-06T16:04:48.860811Z","iopub.status.idle":"2024-05-06T16:04:50.074828Z","shell.execute_reply.started":"2024-05-06T16:04:48.860773Z","shell.execute_reply":"2024-05-06T16:04:50.073971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATASET_COLUMNS = [\"id\", \"entity\", \"sentiment\", \"tweet\"]\n\nhateEvalP_train = pd.read_csv('/kaggle/input/mydataset/train_en.tsv', delimiter='\\t')\nhateTrail_train = pd.read_csv('/kaggle/input/mydataset/trial_en.tsv', delimiter='\\t')\nhateEval_train = pd.concat([hateEvalP_train, hateTrail_train], axis = 0, ignore_index=True)\n\nhateEval_dev = pd.read_csv('/kaggle/input/mydataset/dev_en.tsv', delimiter='\\t')\n\npolarity_train = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv', names=DATASET_COLUMNS)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:50.077033Z","iopub.execute_input":"2024-05-06T16:04:50.077326Z","iopub.status.idle":"2024-05-06T16:04:50.483785Z","shell.execute_reply.started":"2024-05-06T16:04:50.077301Z","shell.execute_reply":"2024-05-06T16:04:50.482925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(hateEval_train))\nprint(len(polarity_train))","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:50.484798Z","iopub.execute_input":"2024-05-06T16:04:50.485093Z","iopub.status.idle":"2024-05-06T16:04:50.490384Z","shell.execute_reply.started":"2024-05-06T16:04:50.485053Z","shell.execute_reply":"2024-05-06T16:04:50.489341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(hateEval_train.columns)\nprint(polarity_train.columns)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:50.491536Z","iopub.execute_input":"2024-05-06T16:04:50.491832Z","iopub.status.idle":"2024-05-06T16:04:50.503520Z","shell.execute_reply.started":"2024-05-06T16:04:50.491810Z","shell.execute_reply":"2024-05-06T16:04:50.502626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hateEval_train['pre_process'] = hateEval_train['text'].apply(pre_process)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:50.504746Z","iopub.execute_input":"2024-05-06T16:04:50.505087Z","iopub.status.idle":"2024-05-06T16:04:54.649104Z","shell.execute_reply.started":"2024-05-06T16:04:50.505057Z","shell.execute_reply":"2024-05-06T16:04:54.648151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neutral_polar = list(polarity_train[polarity_train['sentiment'] == 'Positive']['tweet'])\npostive_polar = list(polarity_train[polarity_train['sentiment'] == 'Neutral']['tweet'])\nnegative_polar = list(polarity_train[polarity_train['sentiment'] == 'Negative']['tweet'])\n\nprint(len(neutral_polar))\nprint(len(postive_polar))\nprint(len(negative_polar))","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:54.650378Z","iopub.execute_input":"2024-05-06T16:04:54.650734Z","iopub.status.idle":"2024-05-06T16:04:54.713534Z","shell.execute_reply.started":"2024-05-06T16:04:54.650703Z","shell.execute_reply":"2024-05-06T16:04:54.712664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\npolarity_data = []\nno = 1900\n\nfor i in range(no):\n    if isinstance(neutral_polar[i], str):\n        polarity_data.append([pre_process(neutral_polar[i]), 0])\n    if isinstance(postive_polar[i], str):\n        polarity_data.append([pre_process(postive_polar[i]), 1])\n    if isinstance(negative_polar[i], str):\n        polarity_data.append([pre_process(negative_polar[i]), 2])\n\nrandom.shuffle(polarity_data)    \nprint(len(polarity_data))","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:54.714798Z","iopub.execute_input":"2024-05-06T16:04:54.715066Z","iopub.status.idle":"2024-05-06T16:04:57.061332Z","shell.execute_reply.started":"2024-05-06T16:04:54.715044Z","shell.execute_reply":"2024-05-06T16:04:57.059994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"polarityData = []\npolarity_label = []\n\nfor a, b in polarity_data:\n    polarityData.append(a)\n    polarity_label.append(b)\n\nprint(len(polarityData))\nprint(len(polarity_label))","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:57.065327Z","iopub.execute_input":"2024-05-06T16:04:57.065668Z","iopub.status.idle":"2024-05-06T16:04:57.074041Z","shell.execute_reply.started":"2024-05-06T16:04:57.065624Z","shell.execute_reply":"2024-05-06T16:04:57.073147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(polarityData[:5], polarity_label[:20])","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:57.075348Z","iopub.execute_input":"2024-05-06T16:04:57.076044Z","iopub.status.idle":"2024-05-06T16:04:57.094019Z","shell.execute_reply.started":"2024-05-06T16:04:57.076019Z","shell.execute_reply":"2024-05-06T16:04:57.093099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertModel\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained(\"bert-base-uncased\")\n\nprint(model)\nprint(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:04:57.094935Z","iopub.execute_input":"2024-05-06T16:04:57.095238Z","iopub.status.idle":"2024-05-06T16:05:07.781361Z","shell.execute_reply.started":"2024-05-06T16:04:57.095214Z","shell.execute_reply":"2024-05-06T16:05:07.780426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:05:07.782719Z","iopub.execute_input":"2024-05-06T16:05:07.783588Z","iopub.status.idle":"2024-05-06T16:05:07.788611Z","shell.execute_reply.started":"2024-05-06T16:05:07.783553Z","shell.execute_reply":"2024-05-06T16:05:07.787533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nBatchSize = 8\nclass MultiTaskData(Dataset):\n    def __init__(self, tweets, labels, no, dic):\n        self.tweets = tweets\n        self.labels = labels\n        self.no = no\n        self.sentiToLabel = dic\n    \n    def __len__(self):\n        return len(self.tweets)\n    \n    def __getitem__(self, ind):\n        output = tokenizer(self.tweets[ind],  max_length = 80,  padding='max_length', truncation=True, return_tensors='pt')\n        input_ids = output['input_ids'][0]\n        attention_mask = output['attention_mask'][0]\n        \n        if self.no == 1: #polarity\n            my_tensor = torch.zeros(3)\n            my_tensor[self.labels[ind]] = 1\n        elif self.no == 2: #sentiment\n            my_tensor = torch.zeros(7)\n            my_tensor[self.sentiToLabel[self.labels[ind]]] = 1\n        else: #hate\n            my_tensor = torch.zeros(2)\n            my_tensor[self.labels[ind]] = 1\n        \n        return input_ids, attention_mask, my_tensor\n            \n            \nhateEval_data = MultiTaskData(hateEval_train['pre_process'], hateEval_train['HS'], 3, None)\npolarity_data = MultiTaskData(polarityData, polarity_label, 1, None)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:05:07.789627Z","iopub.execute_input":"2024-05-06T16:05:07.789905Z","iopub.status.idle":"2024-05-06T16:05:07.806728Z","shell.execute_reply.started":"2024-05-06T16:05:07.789873Z","shell.execute_reply":"2024-05-06T16:05:07.805870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hateEval_load = DataLoader(hateEval_data, BatchSize)\npolarity_load = DataLoader(polarity_data, BatchSize)\n\nprint(len(hateEval_load))\nprint(len(polarity_load))","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:05:07.807929Z","iopub.execute_input":"2024-05-06T16:05:07.808251Z","iopub.status.idle":"2024-05-06T16:05:07.822413Z","shell.execute_reply.started":"2024-05-06T16:05:07.808222Z","shell.execute_reply":"2024-05-06T16:05:07.821559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(polarity_data[0])\nprint(hateEval_data[0]) # each having (input_ids, attention_masks, labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:05:07.823395Z","iopub.execute_input":"2024-05-06T16:05:07.824309Z","iopub.status.idle":"2024-05-06T16:05:07.871588Z","shell.execute_reply.started":"2024-05-06T16:05:07.824280Z","shell.execute_reply":"2024-05-06T16:05:07.870746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MultiTaskModel(nn.Module):\n    def __init__(self, hidden_dim, d_model, output1, output2, output3, drop_prob = 0.1):\n        super().__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        self.relu = nn.ReLU()\n        self.sigmoid = nn.Sigmoid()\n#         self.softmax = nn.Softmax(dim=1)  # we should be using these as the loss needs logits to run\n        \n        # 1 - polarity, 2 - sentiment, 3 - hate\n        self.linear11 = nn.Linear(d_model, hidden_dim)\n        self.dropout11 = nn.Dropout(drop_prob)\n        self.linear12 = nn.Linear(hidden_dim, hidden_dim)\n        self.dropout12 = nn.Dropout(drop_prob)\n        self.linear13 = nn.Linear(hidden_dim, output1)\n        \n        \n        self.linear31 = nn.Linear(d_model, hidden_dim)\n        self.dropout31 = nn.Dropout(drop_prob)\n        self.linear32 = nn.Linear(hidden_dim, hidden_dim)\n        self.dropout32 = nn.Dropout(drop_prob)\n        self.linear33 = nn.Linear(hidden_dim, output3)\n        \n    \n    def forward(self, input_ids, masks, task_no):\n        \n        output = self.bert(input_ids, masks) #[32, 80, 768]\n        output = output['last_hidden_state']\n        cls = output[:,0,:] # [32 x 768]\n        \n        if task_no[0] == 1:\n            y = self.linear11(cls)\n            y = self.relu(y)\n            y = self.dropout11(y)\n            y = self.linear12(y)\n            y = self.relu(y)\n            y = self.dropout12(y)\n            y = self.linear13(y)\n        \n        else:\n            y = self.linear31(cls)\n            y = self.relu(y)\n            y = self.dropout31(y)\n            y = self.linear32(y)\n            y = self.relu(y)\n            y = self.dropout32(y)\n            y = self.linear33(y)\n            \n        \n        return y\n\n \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = MultiTaskModel(200, 768, 3, 7, 2)\nmodel = model.to(device)\ncross_criterion = nn.CrossEntropyLoss()\nbce_criterion = nn.BCELoss()\n\n\noptimizer_polarity = optim.AdamW([\n                                    {'params' : model.bert.parameters()},\n                                    {'params' : model.linear11.parameters()},\n                                    {'params' : model.dropout11.parameters()},\n                                    {'params' : model.linear12.parameters()},\n                                    {'params' : model.dropout12.parameters()},\n                                    {'params' : model.linear13.parameters()}\n                       \n                                  ], lr=1e-4, weight_decay=0.01\n                                )\n\noptimizer_hate = optim.AdamW([\n                                    {'params' : model.bert.parameters()},\n                                    {'params' : model.linear31.parameters()},\n                                    {'params' : model.dropout31.parameters()},\n                                    {'params' : model.linear32.parameters()},\n                                    {'params' : model.dropout32.parameters()},\n                                    {'params' : model.linear33.parameters()},\n                       \n                                  ], lr=1e-4, weight_decay=0.01\n                                )\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:05:07.872600Z","iopub.execute_input":"2024-05-06T16:05:07.872859Z","iopub.status.idle":"2024-05-06T16:05:08.627488Z","shell.execute_reply.started":"2024-05-06T16:05:07.872839Z","shell.execute_reply":"2024-05-06T16:05:08.626440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getData(data, i):\n    if i >= len(data):\n        return None, None, None\n    \n    for j, (input_ids, mask, labels) in enumerate(data):\n        if i == j:\n            return input_ids, mask, labels\n    \n    return None, None, None","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:05:08.628812Z","iopub.execute_input":"2024-05-06T16:05:08.629133Z","iopub.status.idle":"2024-05-06T16:05:08.634414Z","shell.execute_reply.started":"2024-05-06T16:05:08.629108Z","shell.execute_reply":"2024-05-06T16:05:08.633510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preparing evalutaion dataset\ndata = list(hateEval_dev['text'])\nlabel = list(hateEval_dev['HS'])\ndev_data = []\ndev_label = []\nfor i, x in enumerate(data):\n    if len(dev_data) > 32:\n        break\n    elif isinstance(x, str):\n        dev_data.append(pre_process(x))\n        dev_label.append(label[i])\n    \nhateEval_dev_dataset = MultiTaskData(dev_data, dev_label, 3, None)\nhateEval_dev_load = DataLoader(hateEval_dev_dataset, len(dev_data))","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:05:08.635439Z","iopub.execute_input":"2024-05-06T16:05:08.635729Z","iopub.status.idle":"2024-05-06T16:05:08.663040Z","shell.execute_reply.started":"2024-05-06T16:05:08.635706Z","shell.execute_reply":"2024-05-06T16:05:08.662140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torcheval-nightly","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:05:08.664118Z","iopub.execute_input":"2024-05-06T16:05:08.665731Z","iopub.status.idle":"2024-05-06T16:05:21.595950Z","shell.execute_reply.started":"2024-05-06T16:05:08.665707Z","shell.execute_reply":"2024-05-06T16:05:21.594827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torcheval\nfrom torcheval.metrics.functional import multiclass_confusion_matrix\n\npolarity_accuracy = torcheval.metrics.MulticlassAccuracy(num_classes = 3, device = device)\npolarity_f1Score = torcheval.metrics.MulticlassF1Score(num_classes = 3, device = device)\npolarity_confusion_matrix = torcheval.metrics.MulticlassConfusionMatrix(num_classes = 3, device = device)\n\nhate_accuracy = torcheval.metrics.MulticlassAccuracy(num_classes = 2 , device = device)\nhate_f1Score = torcheval.metrics.MulticlassF1Score(num_classes = 2, device = device)\nhate_confusion_matrix = torcheval.metrics.MulticlassConfusionMatrix(num_classes = 2, device = device)\n\n\nhate_accuracy_dev = torcheval.metrics.MulticlassAccuracy(num_classes = 2 , device = device)\nhate_f1Score_dev = torcheval.metrics.MulticlassF1Score(num_classes = 2, device = device)\nhate_confusion_matrix_dev = torcheval.metrics.MulticlassConfusionMatrix(num_classes = 2, device = device)\n\nupper_limit = 256 # 175 -- 32 size\nEPOCHS = 3\nthreshold = 0.5 \n\nlossPerEpoch = []\n\n\nfor i in range(EPOCHS):\n    \n    lossList = []\n    for j in range(upper_limit):\n        \n        if i < 2:\n            for param in model.bert.parameters():\n                param.requires_grad = False\n        elif i == 2:\n            for param in model.bert.parameters():\n                param.requires_grad = True\n            \n            \n        model.train()\n        loss = 0\n        \n        input_ids, masks, label = getData(polarity_load, j)\n        task_no = torch.zeros(3)\n        task_no[0] = 1\n        if input_ids != None:\n            \n            input_ids, masks, task_no = input_ids.to(device), masks.to(device), task_no.to(device)\n            output = model.forward(input_ids, masks, task_no)\n            predictions = torch.argmax(output, dim=1)\n            label_ground = label.squeeze().int()\n            predictions, label_ground, output, label = predictions.to(device), label_ground.to(device), output.to(device), label.to(device)\n            \n            \n            loss = cross_criterion(output, label)\n            print(loss, 0)\n            optimizer_polarity.zero_grad()\n            loss.backward()\n            optimizer_polarity.step()\n\n        \n        input_ids, masks, label = getData(hateEval_load, j)\n        task_no = torch.zeros(3)\n        task_no[2] = 1\n        if input_ids != None:\n            \n            input_ids, masks, task_no = input_ids.to(device), masks.to(device), task_no.to(device)\n            output = model.forward(input_ids, masks, task_no)\n            predictions = torch.argmax(output, dim=1)\n            label_ground = torch.argmax(label, dim=1)\n            print(predictions, label_ground)\n            output, label = output.to(device), label.to(device)\n\n            predictions, label_ground = predictions.to(device), label_ground.to(device)\n            hate_accuracy.update(predictions, label_ground)\n            hate_f1Score.update(predictions, label_ground)\n            hate_confusion_matrix.update(predictions, label_ground)\n            \n            loss = cross_criterion(output, label)\n            lossList.append(loss)\n            print(loss, 2)\n            optimizer_hate.zero_grad()\n            loss.backward()\n            optimizer_hate.step()\n            \n        \n    accuracy = hate_accuracy.compute()\n    f1_score = hate_f1Score.compute()\n    confusion_matrix = hate_confusion_matrix.compute()\n        \n\n    model.eval()\n    eval_loss = 0\n    \n    task_no = torch.zeros(3)\n    task_no[2] = 1\n    for input_ids, masks, labels in hateEval_dev_load:\n            \n        input_ids, masks, task_no = input_ids.to(device), masks.to(device), task_no.to(device)\n        output = model.forward(input_ids, masks, task_no)\n        predictions = torch.argmax(output, dim=1)\n        label_ground = torch.argmax(labels, dim=1)\n        print(predictions, label_ground)\n        output, label = output.to(device), labels.to(device)\n            \n        predictions, label_ground = predictions.to(device), label_ground.to(device)\n        eval_loss += cross_criterion(output, label)\n        hate_accuracy_dev.update(predictions, label_ground)\n        hate_f1Score_dev.update(predictions, label_ground)\n        hate_confusion_matrix_dev.update(predictions, label_ground)\n    \n    accuracy_dev = hate_accuracy_dev.compute()\n    f1_score_dev = hate_f1Score_dev.compute()\n    confusion_matrix_dev =  hate_confusion_matrix_dev.compute()\n    \n    hate_accuracy.reset()\n    hate_f1Score.reset()\n    hate_confusion_matrix.reset()\n    \n    hate_accuracy_dev.reset()\n    hate_f1Score_dev.reset()\n    hate_confusion_matrix_dev.reset()\n    \n    lossPerEpoch.append(sum(lossList)/len(lossList))\n        \n    print(i, eval_loss, loss)\n    print(accuracy, f1_score, confusion_matrix)\n    print(accuracy_dev, f1_score_dev, confusion_matrix_dev)\n        \n        \n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:05:21.597560Z","iopub.execute_input":"2024-05-06T16:05:21.597892Z","iopub.status.idle":"2024-05-06T16:32:13.733719Z","shell.execute_reply.started":"2024-05-06T16:05:21.597859Z","shell.execute_reply":"2024-05-06T16:32:13.732704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hateEval_test = pd.read_csv('/kaggle/input/mydataset/test_en.tsv', delimiter='\\t')\nhateEval_labels = pd.read_csv('/kaggle/input/mydataset/en_a.tsv', delimiter='\\t', header=None)\nhateEval_test['pre_process'] = hateEval_test['text'].apply(pre_process)\nhateEval_data = MultiTaskData(hateEval_test['pre_process'], hateEval_labels[1], 3, None)\nhateEval_test_load = DataLoader(hateEval_data, 8)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:32:13.734878Z","iopub.execute_input":"2024-05-06T16:32:13.735354Z","iopub.status.idle":"2024-05-06T16:32:15.189707Z","shell.execute_reply.started":"2024-05-06T16:32:13.735328Z","shell.execute_reply":"2024-05-06T16:32:15.188872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hate_accuracy_test = torcheval.metrics.MulticlassAccuracy(num_classes = 2 , device = device)\nhate_f1Score_test = torcheval.metrics.MulticlassF1Score(num_classes = 2, device = device)\nhate_confusion_matrix_test = torcheval.metrics.MulticlassConfusionMatrix(num_classes = 2, device = device)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:32:15.190753Z","iopub.execute_input":"2024-05-06T16:32:15.191010Z","iopub.status.idle":"2024-05-06T16:32:15.198218Z","shell.execute_reply.started":"2024-05-06T16:32:15.190988Z","shell.execute_reply":"2024-05-06T16:32:15.197471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"task_no = torch.zeros(3)\ntask_no[2] = 1\ntask_no = task_no.to(device)\n\nfor j, (input_ids, masks, labels) in enumerate(hateEval_test_load):\n        input_ids, masks = input_ids.to(device), masks.to(device)\n        output = model.forward(input_ids, masks, task_no)\n        predictions = torch.argmax(output, dim=1)\n        label_ground = torch.argmax(labels, dim=1)\n        print(predictions, label_ground)\n        output, label = output.to(device), labels.to(device)\n            \n        predictions, label_ground = predictions.to(device), label_ground.to(device)\n        hate_accuracy_test.update(predictions, label_ground)\n        hate_f1Score_test.update(predictions, label_ground)\n        hate_confusion_matrix_test.update(predictions, label_ground)\n        \naccuracy_test = hate_accuracy_test.compute()\nf1_score_test = hate_f1Score_test.compute()\nconfusion_matrix_test =  hate_confusion_matrix_test.compute()\n    \nhate_accuracy_test.reset()\nhate_f1Score_test.reset()\nhate_confusion_matrix_test.reset()\n   \nprint(accuracy_test, f1_score_test, confusion_matrix_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:32:15.199242Z","iopub.execute_input":"2024-05-06T16:32:15.199514Z","iopub.status.idle":"2024-05-06T16:32:27.525358Z","shell.execute_reply.started":"2024-05-06T16:32:15.199475Z","shell.execute_reply":"2024-05-06T16:32:27.524507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nfilepath = '/kaggle/working/hateSpeechPolarity.pth'\n\ntorch.save(model, filepath)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:32:27.526531Z","iopub.execute_input":"2024-05-06T16:32:27.526816Z","iopub.status.idle":"2024-05-06T16:32:28.119665Z","shell.execute_reply.started":"2024-05-06T16:32:27.526792Z","shell.execute_reply":"2024-05-06T16:32:28.118680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nlossItems = list()\nfor loss in lossPerEpoch:\n    lossItems.append(loss.item())\nlossItems = torch.tensor(lossItems)\nepochs = torch.arange(len(lossItems))+1\nprint(epochs)\nplt.plot(epochs,lossItems)\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.xticks(range(1, len(lossItems) + 1))\nplt.title('Epochs vs Loss')\nplt.xticks(range(1, len(lossItems) + 1))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T02:31:01.806988Z","iopub.execute_input":"2024-05-07T02:31:01.807420Z","iopub.status.idle":"2024-05-07T02:31:02.237731Z","shell.execute_reply.started":"2024-05-07T02:31:01.807385Z","shell.execute_reply":"2024-05-07T02:31:02.236379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Given data\nlossItems = [0.605, 0.508, 0.497]\nepochs = [1, 2, 3]\n\n# Plot\nplt.plot(epochs, lossItems)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.xticks(range(1, len(lossItems) + 1))\nplt.title('Epochs vs Loss')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-07T02:32:57.835776Z","iopub.execute_input":"2024-05-07T02:32:57.837122Z","iopub.status.idle":"2024-05-07T02:32:58.160213Z","shell.execute_reply.started":"2024-05-07T02:32:57.837067Z","shell.execute_reply":"2024-05-07T02:32:58.159358Z"},"trusted":true},"execution_count":null,"outputs":[]}]}